import os
import json
import re
import requests

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
OUTPUT_JSON = os.path.join(BASE_DIR, "master_registry.json")
GH_REPO = "MidoN37/daily-scraper-krok"

def clean_title(text):
    text = re.sub(r'(Krok|–ö—Ä–æ–∫)\s*([123])', r'–ö–†–û–ö \2', text, flags=re.IGNORECASE)
    words = text.split()
    final = []
    for w in words:
        if not final or w.lower() != final[-1].lower(): final.append(w)
    return ' '.join(final).strip()

def get_type(filename):
    booklet_keywords = ["—É—Å—ñ –±—É–∫–ª–µ—Ç–∏", "all booklets", "–≤—Å–µ –±—É–∫–ª–µ—Ç—ã", "merged", "live"]
    return "booklet" if any(k in filename.lower() for k in booklet_keywords) else "base"

def get_master_list():
    master_list = []

    # 1. Fetch Live Data from GitHub (–ë–∞–∑–∞ –∑ –¶–¢)
    print("üåê Fetching Live Data from GitHub...")
    try:
        res = requests.get(f"https://api.github.com/repos/{GH_REPO}/contents/Merged/PDF")
        if res.status_code == 200:
            for f in res.json():
                if not f['name'].lower().endswith(".pdf"): continue
                name = f['name'].replace(".pdf", "")
                exam_type = "Krok English" if "(EN)" in name.upper() else "–ö—Ä–æ–∫ –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞"
                if "–Ñ–î–ö–Ü" in name: exam_type = "–Ñ–î–ö–Ü"
                if "–ê–ú–ü–°" in name: exam_type = "–ê–ú–ü–°"
                
                level = "–Ü–Ω—à–µ"
                if "–ö–†–û–ö 1" in name.upper(): level = "–ö–†–û–ö 1"
                elif "–ö–†–û–ö 2" in name.upper(): level = "–ö–†–û–ö 2"
                elif "–ö–†–û–ö 3" in name.upper(): level = "–ö–†–û–ö 3"
                elif "–ë–∞–∫–∞–ª–∞–≤—Ä–∏" in name: level = "–Ñ–î–ö–Ü –ë–∞–∫–∞–ª–∞–≤—Ä–∏"
                elif "–§–∞—Ö–æ–≤–∞" in name: level = "–Ñ–î–ö–Ü –§–∞—Ö–æ–≤–∞ –ø–µ—Ä–µ–¥–≤–∏—â–∞ –æ—Å–≤—ñ—Ç–∞"

                master_list.append({
                    "name": clean_title(name), "source": "–ë–∞–∑–∞ –∑ –¶–¢", "path": f['download_url'],
                    "exam_type": exam_type, "level": level, "subject": "–ù–æ–≤—ñ —Ç–µ—Å—Ç–∏", "type": "booklet"
                })
    except Exception as e:
        print(f"Error fetching GitHub data: {e}")

    # 2. Index local folders (–ó–≤–∏—á–∞–π–Ω—ñ –ë–∞–∑—ñ & –°—Ç–∞—Ä—à–µ –¶–¢)
    local_sources = ["–ó–≤–∏—á–∞–π–Ω—ñ –ë–∞–∑—ñ", "–°—Ç–∞—Ä—à–µ –¶–¢"]
    for source_name in local_sources:
        root_path = os.path.join(BASE_DIR, source_name)
        if not os.path.exists(root_path): continue
        
        for root, dirs, files in os.walk(root_path):
            for f in files:
                if f.lower().endswith(".pdf"):
                    rel_path = os.path.relpath(os.path.join(root, f), BASE_DIR)
                    parts = rel_path.split(os.sep)
                    
                    if source_name == "–ó–≤–∏—á–∞–π–Ω—ñ –ë–∞–∑—ñ" and "PDF Merged" in root:
                        # [–ó–≤–∏—á–∞–π–Ω—ñ –ë–∞–∑—ñ, Lang, PDF Merged, Level, Subject, file]
                        lang = "Krok English" if parts[1] == "English" else ("–ú–æ—Å–∫–æ–≤—Å—å–∫–∞" if parts[1] == "–ú–æ—Å–∫–æ–≤—Å—å–∫–∞" else "–ö—Ä–æ–∫ –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞")
                        level = clean_title(parts[3])
                        subject = parts[4]
                        exam_type = "–Ñ–î–ö–Ü" if "–Ñ–î–ö–Ü" in level else lang
                        
                        master_list.append({
                            "name": clean_title(f"{level} {subject} - {f.replace('.pdf', '')}"),
                            "source": source_name, "path": rel_path,
                            "exam_type": exam_type, "level": level, "subject": subject, "type": get_type(f)
                        })

                    elif source_name == "–°—Ç–∞—Ä—à–µ –¶–¢" and (root.lower().endswith(os.sep + "pdf") or "—î–¥–∫—ñ" in root.lower()):
                         # Standardized logic for Older database
                        rel = os.path.relpath(os.path.join(root, f), BASE_DIR)
                        p = rel.split(os.sep)
                        if p[1].lower() == "—î–¥–∫—ñ":
                            level = clean_title(p[2])
                            subject = p[3]
                            exam_type = "–Ñ–î–ö–Ü"
                        else:
                            level = clean_title(p[1])
                            subject = p[2]
                            exam_type = "–ö—Ä–æ–∫ –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞"

                        master_list.append({
                            "name": clean_title(f"{level} {subject}"),
                            "source": source_name, "path": rel,
                            "exam_type": exam_type, "level": level, "subject": subject, "type": "booklet"
                        })

    return master_list

if __name__ == "__main__":
    data = get_master_list()
    with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    print(f"‚úÖ Build Complete: Indexed {len(data)} files.")